<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A Comprehensive Dataset and Benchmark forEthiopic/Amharic Scene Text Detection andRecognition" />
<meta property="og:description" content="A Comprehensive Dataset and Benchmark forEthiopic/Amharic Scene Text Detection andRecognition" />
<meta name="twitter:card" content="summary" />
<script type="application/ld+json">
{"url":"/","description":"A Comprehensive Dataset and Benchmark forEthiopic/Amharic Scene Text Detection andRecognition","@type":"WebSite","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="./assets/css/style.css?v=">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name"></h1>
      <h2 class="project-tagline">A Comprehensive Dataset and Benchmark forEthiopic/Amharic Scene Text Detection andRecognition</h2>


â€‹      
    </header>
    
    <main id="content" class="main-content" role="main">
      <h1 id="hust-astd">HUST-ASTD</h1>

<p>In this work, we presented four datasets named HUST-ART, HUST-AST, ABE, and Tana for Amharic script detection and recognition in the nature scene. The proposed datasets are the first comprehensive and public Amharic script datasets to the best of our knowledge. These datasets will promote the development of robust Amharic script detection and recognition algorithms. Consequently, the outcome will benefit people in East Africa, including diplomats from several countries and international communities. For detailed analysis and information, please refer to the <a href="supplementary/supplementary.pdf">supplementary document</a>.</p>

<h2 id="download-datasets">Download datasets:</h2>

<p>Detection part:<br />
HUST-ART[<a href="https://pan.baidu.com/s/1qt6zQBITVaZQQucq1lkCJg">Baidu</a>], passwd: 8wns or  [<a href="https://1drv.ms/u/s!AgGaEVjXyVXwao_owSrMXIZtVKI?e=14whRb">OneDrive</a>]<br />
HUST-AST[<a href="https://pan.baidu.com/s/1qt6zQBITVaZQQucq1lkCJg">Baidu</a>], passwd: 8wns or  [<a href="https://1drv.ms/u/s!ArX3oeMKNXLsiNApi9yL0QQsrj1XWw?e=Q694xJ">OneDrive</a>]</p>

<p>Recognition part:<br />
HUST-ART[<a href="https://pan.baidu.com/s/1w6ZHRHS7e6ZKx1wH2C0I2g">Baidu</a>], passwd:k6wj or [<a href="https://1drv.ms/u/s!ArX3oeMKNXLsiNAoRkGfGCmJJiVS0Q?e=AobKsJ">OneDrive</a>]<br />
ABE[<a href="https://pan.baidu.com/s/1w6ZHRHS7e6ZKx1wH2C0I2g">Baidu</a>], passwd:k6wj or [<a href="https://1drv.ms/u/s!ArX3oeMKNXLsiNAqlwK4jSVpFCXMKA?e=dRMC74">OneDrive</a>]<br />
TANA[<a href="https://pan.baidu.com/s/1qt6zQBITVaZQQucq1lkCJg">Baidu</a>], passwd: 8wns or  [<a href="https://1drv.ms/u/s!AgGaEVjXyVXwao_owSrMXIZtVKI?e=14whRb">OneDrive</a>]</p>

<h2 id="dataset-highlights">Dataset Highlights</h2>
<p><img src="images/intro.jpg" alt="Octocat" /></p>

<h3 id="hust-art">HUST-ART</h3>

<p>The comparisons of HUST-ART and other datasets:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Dataset</th>
      <th style="text-align: left">Language</th>
      <th>Text shape</th>
      <th style="text-align: left">Total images</th>
      <th>Cropped words</th>
      <th>Total instances</th>
      <th>Av. Instances</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">ICDAR-2013</td>
      <td style="text-align: left">ENG</td>
      <td>Horizontal</td>
      <td style="text-align: left">462</td>
      <td>1,503</td>
      <td>1,943</td>
      <td>4.2</td>
    </tr>
    <tr>
      <td style="text-align: left">ICDAR-2015</td>
      <td style="text-align: left">ENG</td>
      <td>Oriented</td>
      <td style="text-align: left">1500</td>
      <td>6,545</td>
      <td>1,1886</td>
      <td>7.9</td>
    </tr>
    <tr>
      <td style="text-align: left">MLT17</td>
      <td style="text-align: left">ENG/CHN</td>
      <td>Oriented</td>
      <td style="text-align: left">12,514</td>
      <td>84,868</td>
      <td>107,537</td>
      <td>8.6</td>
    </tr>
    <tr>
      <td style="text-align: left">Total-Text</td>
      <td style="text-align: left">ENG</td>
      <td>Cruved</td>
      <td style="text-align: left">1,555</td>
      <td>9,330</td>
      <td>11,459</td>
      <td>6.0</td>
    </tr>
    <tr>
      <td style="text-align: left">Addis et al.</td>
      <td style="text-align: left">Amharic</td>
      <td>-</td>
      <td style="text-align: left">-</td>
      <td>2,500</td>
      <td>-</td>
      <td>-</td>
    </tr>
    <tr>
      <td style="text-align: left">HUST-ART</td>
      <td style="text-align: left">Amharic</td>
      <td>Oriented</td>
      <td style="text-align: left">2,200</td>
      <td>11,254</td>
      <td>14,069</td>
      <td>6.4</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>The first real world Amharic detection dataset.</li>
  <li>Contain 2,200 natural scenes images.</li>
  <li>A total of 11,254 cropped text instances.</li>
  <li>Comprises diversified scenes, including signboards, posters, indoors, streets, etc.</li>
</ul>

<h3 id="hust-ast">HUST-AST</h3>
<ul>
  <li>The first synthetic  Amharic detection dataset.</li>
  <li>Contain 75,904 images</li>
  <li>A total of 829394 cropped synthetic text instances.</li>
  <li>Various scenes and typeface.</li>
</ul>

<h3 id="visualizations-of-detection">Visualizations of Detection</h3>
<p><img src="images/detection_results.jpg" alt="Octocat" /></p>

<h3 id="abe">ABE</h3>
<ul>
  <li>The first real world Amharic recognition dataset.</li>
  <li>Contain 12,839 real-word text images: 7,621 for training and  5,218 for testing.</li>
  <li>Various scenes</li>
</ul>

<h3 id="tana">Tana</h3>
<ul>
  <li>The first diverse and large synthetic Amharic recognition dataset.</li>
  <li>Consists of 2851778 synthetic word images, including the 829394 HUST-AST cropped text images.</li>
  <li>Various scenes.</li>
</ul>

<h3 id="visualizations-of-recognition">Visualizations of Recognition</h3>
<p><img src="images/recognition_results.jpg" alt="Octocat" /></p>

<h3 id="visualizations-of-recognition-1">Visualizations of Recognition</h3>
<p><img src="images/end_to_end_results.jpg" alt="Octocat" /></p>

<h2 id="leaderboard-of-detection">Leaderboard of detection</h2>

<p>Results on HUST-ART dataset:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Method</th>
      <th style="text-align: left">Backbone</th>
      <th style="text-align: left">Precision</th>
      <th>Recall</th>
      <th>F1-measure</th>
      <th>FPS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">EAST</td>
      <td style="text-align: left">Res50</td>
      <td style="text-align: left">79.67</td>
      <td>79.10</td>
      <td>79.38</td>
      <td>-</td>
    </tr>
    <tr>
      <td style="text-align: left">PSENET</td>
      <td style="text-align: left">Res50</td>
      <td style="text-align: left">94.79</td>
      <td>72.21</td>
      <td>81.97</td>
      <td>-</td>
    </tr>
    <tr>
      <td style="text-align: left">PAN</td>
      <td style="text-align: left">Res18</td>
      <td style="text-align: left">95.21</td>
      <td>73.52</td>
      <td>82.97</td>
      <td>28</td>
    </tr>
    <tr>
      <td style="text-align: left">DB</td>
      <td style="text-align: left">Res18</td>
      <td style="text-align: left">96.61</td>
      <td>73.67</td>
      <td>83.60</td>
      <td>50</td>
    </tr>
    <tr>
      <td style="text-align: left">DB</td>
      <td style="text-align: left">Res50</td>
      <td style="text-align: left">95.31</td>
      <td>74.62</td>
      <td>83.71</td>
      <td>22</td>
    </tr>
  </tbody>
</table>

<h2 id="leaderboard-of-recognition">Leaderboard of recognition</h2>

<p>Results on ABE dataset:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Method</th>
      <th style="text-align: left">Accuracy (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">CRNN</td>
      <td style="text-align: left">75.91</td>
    </tr>
    <tr>
      <td style="text-align: left">RARE</td>
      <td style="text-align: left">78.13</td>
    </tr>
    <tr>
      <td style="text-align: left">ASTER</td>
      <td style="text-align: left">81.4</td>
    </tr>
    <tr>
      <td style="text-align: left">SATRN</td>
      <td style="text-align: left">85.66</td>
    </tr>
    <tr>
      <td style="text-align: left">MASTER</td>
      <td style="text-align: left">86.5</td>
    </tr>
  </tbody>
</table>

<p>Results on HUST-ART dataset:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Method</th>
      <th style="text-align: left">Accuracy (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">CRNN</td>
      <td style="text-align: left">80.26</td>
    </tr>
    <tr>
      <td style="text-align: left">RARE</td>
      <td style="text-align: left">82.05</td>
    </tr>
    <tr>
      <td style="text-align: left">ASTER</td>
      <td style="text-align: left">85.3</td>
    </tr>
    <tr>
      <td style="text-align: left">SATRN</td>
      <td style="text-align: left">87.54</td>
    </tr>
    <tr>
      <td style="text-align: left">MASTER</td>
      <td style="text-align: left">87.7</td>
    </tr>
  </tbody>
</table>

<h2 id="leaderboard-of-end-to-end-detection-and-recognition">Leaderboard of End-to-end detection and recognition</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Method</th>
      <th style="text-align: left">E2E</th>
      <th style="text-align: left">Precision</th>
      <th>Recall</th>
      <th>F1-measure</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">PAN++</td>
      <td style="text-align: left">30.31</td>
      <td style="text-align: left">93.38</td>
      <td>30.06</td>
      <td>45.48</td>
    </tr>
    <tr>
      <td style="text-align: left">Mask TextSpotter v3</td>
      <td style="text-align: left">81.71</td>
      <td style="text-align: left">88.31</td>
      <td>80.82</td>
      <td>84.40</td>
    </tr>
  </tbody>
</table>

<p>E2E refer to the End-to-end recognition accuracy rate.</p>
<h2 id="contact">Contact</h2>
<p>Send an email to myethiopia2025@gmail.com for any queries.</p>



      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
  </body>
</html>
